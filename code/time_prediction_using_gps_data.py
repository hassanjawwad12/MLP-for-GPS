# -*- coding: utf-8 -*-
"""Time Prediction using GPS Data.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1m5xd8xOnNPQNjMvkPJCJnla_SvMvo-MK
"""

import pandas as pd
import numpy as np

data=pd.read_csv('data.csv')

data.head()

data.tail()

data.columns

data.shape

data.describe()

data.info()

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense
from sklearn.preprocessing import MinMaxScaler
from sklearn.preprocessing import LabelEncoder,StandardScaler
from sklearn.neural_network import MLPClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

data["arrival_label"] = data["AppCode"].astype(str) + "_" + data["StopID"].astype(str)

# Label encode the combined label
le = LabelEncoder()
data["arrival_label"] = le.fit_transform(data["arrival_label"])

features = ["Lat", "Lng", "Speed","DirectionDegrees"]
target = "arrival_label"

data["LVDateTime"] = pd.to_datetime(data["LVDateTime"])

# Separate features and target
X = data[features]
y = data[target]

station_ids = data["StopID"].astype(int) // 21  # Cast StopID to integer before division

# Add the station ID as a new feature to the data
data["StationName"] = station_ids

# Standardize features
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Define sequence length
sequence_length = 1

sequences = []
targets = []
for i in range(len(X_scaled) - sequence_length):
    # Consider station ID when selecting data for the sequence
    if i % 21 == 0:  # Check if it's the first data point for a new station
        station_start = i
    sequence = X_scaled[station_start:station_start + sequence_length]
    sequences.append(sequence)
    targets.append(y[station_start + sequence_length - 1])

# Convert sequences and targets to numpy arrays
sequences = np.array(sequences)
targets = np.array(targets)

if len(sequences) < len(y):
  y = y.iloc[:len(sequences)]
  print("Data size adjusted by dropping missing values from y.")

print(f"Sequences shape: {sequences.shape}, y shape: {y.shape}")

# Reshape sequences to fit the MLP input requirements
sequences = sequences.reshape(sequences.shape[0], -1)

# Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(sequences, targets, test_size=0.2, random_state=42)

# Initialize and train the MLP classifier
mlp = MLPClassifier(hidden_layer_sizes=(100,), max_iter=300, alpha=0.0001,
                    solver='adam', random_state=42, tol=1e-4)
mlp.fit(X_train, y_train)

# Predict on the test set
y_pred = mlp.predict(X_test)

# Evaluate the model
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy: {accuracy}")

# Predict on the test set
y_pred = mlp.predict(X_test)
print(y_pred)

import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler
from sklearn.neural_network import MLPClassifier

# Sample data: lat, long, speed, distance
sample_data = {
    "Lat": [38.567711],
    "Lng": [-92.164719],
    "Speed": [16.48],
    "DirectionDegrees": [221.42]
}

# Convert sample data to DataFrame
sample_df = pd.DataFrame(sample_data)

# Repeat the sample data 10 times to create a sequence of length 10
sample_sequence = pd.concat([sample_df], ignore_index=True)

# Standardize the sample sequence using the same scaler used during training
sample_scaled = scaler.transform(sample_sequence)

# Reshape the sample sequence to match the input shape expected by the MLP model
sample_scaled = sample_scaled.reshape(1, -1)

# Predict the target label for the sample sequence
predicted_label = mlp.predict(sample_scaled)

original_label = le.inverse_transform(predicted_label)

print(f"Predicted Label: {predicted_label}")
print(f"Original Label: {original_label}")

data2=pd.read_csv('data2.csv')

import pandas as pd
from geopy.distance import geodesic

def calculate_bearing(lat1, lon1, lat2, lon2):
    # Convert latitude and longitude from degrees to radians
    lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])

    # Compute differences
    dlon = lon2 - lon1
    dlat = lat2 - lat1

    # Calculate bearing
    x = np.sin(dlon) * np.cos(lat2)
    y = np.cos(lat1) * np.sin(lat2) - np.sin(lat1) * np.cos(lat2) * np.cos(dlon)
    initial_bearing = np.arctan2(x, y)

    # Convert from radians to degrees and normalize
    initial_bearing = np.degrees(initial_bearing)
    bearing = (initial_bearing + 360) % 360

    return round(bearing, 2)

def add_bearing_to_df(df):
    # Shift the latitudes and longitudes to line up each point with the next one
    df['next_lat'] = df['vLat'].shift(-1)
    df['next_long'] = df['vLong'].shift(-1)

    # Calculate bearing for each row
    df['DirectionDegrees'] = df.apply(lambda row: calculate_bearing(row['vLat'], row['vLong'], row['next_lat'], row['next_long']) if not pd.isna(row['next_lat']) else np.nan, axis=1)

    # Drop the next_lat and next_long columns as they are no longer needed
    df.drop(['next_lat', 'next_long'], axis=1, inplace=True)

    return df

data2.head(30)

add_bearing_to_df(data2)

data2.rename(columns={
    'dSpeed': 'Speed',
    'vLat': 'Lat',
    'vLong': 'Lng'
}, inplace=True)

data2=data2.dropna()

import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.neural_network import MLPClassifier

sequence_length = 1

predicted_labels = []

for i in range(len(data2) - sequence_length + 1):
    current_sequence = data2.iloc[i:i + sequence_length][['Lat', 'Lng', 'Speed', 'DirectionDegrees']]

    current_sequence_scaled = scaler.transform(current_sequence)

    current_sequence_scaled = current_sequence_scaled.reshape(1, -1)

    predicted_label = mlp.predict(current_sequence_scaled)

    original_label = le.inverse_transform(predicted_label)

    predicted_labels.append(original_label[0])

data2['Predicted_Label'] = pd.Series(predicted_labels, index=data2.index[:len(predicted_labels)])

data2.to_csv('full_data_with_predictions.csv', index=False)

print("Predictions added to the DataFrame and saved to 'full_data_with_predictions.csv'")

df=pd.read_csv('full_data_with_predictions.csv')

df.head(5)

import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.neural_network import MLPClassifier

sequence_length = 1

predicted_labels = []
prediction_confidences = []

for i in range(len(data2) - sequence_length + 1):
    current_sequence = data2.iloc[i:i + sequence_length][['Lat', 'Lng', 'Speed', 'DirectionDegrees']]

    current_sequence_scaled = scaler.transform(current_sequence)

    current_sequence_scaled = current_sequence_scaled.reshape(1, -1)

    predicted_label_proba = mlp.predict_proba(current_sequence_scaled)
    predicted_label = mlp.predict(current_sequence_scaled)

    original_label = le.inverse_transform(predicted_label)

    predicted_labels.append(original_label[0])
    prediction_confidences.append(predicted_label_proba.max())

data2['Predicted_Label'] = pd.Series(predicted_labels, index=data2.index[:len(predicted_labels)])
data2['Prediction_Confidence'] = pd.Series(prediction_confidences, index=data2.index[:len(prediction_confidences)])

data2.to_csv('result.csv', index=False)

df=pd.read_csv('result.csv')

df.head(10)